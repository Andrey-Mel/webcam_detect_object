{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eec76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Using cached pynput-1.8.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from pynput) (1.17.0)\n",
      "Using cached pynput-1.8.1-py2.py3-none-any.whl (91 kB)\n",
      "Installing collected packages: pynput\n",
      "Successfully installed pynput-1.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43bd842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\anaconda3\\envs\\env_detect_drone\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d6f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import torch\n",
    "import time\n",
    "from pynput import keyboard\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f08dab",
   "metadata": {},
   "source": [
    "Тестирорвание сохранения видео из одной камеры как с предсказанием детектирования объектов так и без них. Потому что скорость видео разная, нужно найти почему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc327ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = YOLO('yolo11m.pt')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1623c5e",
   "metadata": {},
   "source": [
    "export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e57724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 'dynamic=True' model with 'nms=True' requires max batch size, i.e. 'batch=16'\n",
      "YOLO11m summary (fused): 125 layers, 20,091,712 parameters, 0 gradients, 68.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (38.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.59', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "Collecting onnx<1.18.0,>=1.12.0\n",
      "  Downloading onnx-1.17.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxslim>=0.1.59\n",
      "  Downloading onnxslim-0.1.65-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.22.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from onnx<1.18.0,>=1.12.0) (2.1.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from onnx<1.18.0,>=1.12.0) (6.31.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from onnxslim>=0.1.59) (1.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from onnxslim>=0.1.59) (25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from onnxslim>=0.1.59) (0.4.6)\n",
      "Collecting coloredlogs (from onnxruntime-gpu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime-gpu)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pc\\anaconda3\\envs\\env_detect_drone\\lib\\site-packages (from sympy>=1.13.3->onnxslim>=0.1.59) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading onnx-1.17.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 14.5/14.5 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading onnxslim-0.1.65-py3-none-any.whl (164 kB)\n",
      "Downloading onnxruntime_gpu-1.22.0-cp310-cp310-win_amd64.whl (214.9 MB)\n",
      "   ---------------------------------------- 214.9/214.9 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: flatbuffers, pyreadline3, onnx, onnxslim, humanfriendly, coloredlogs, onnxruntime-gpu\n",
      "   ---------------------------------------- 7/7 [onnxruntime-gpu]\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.22.0 onnxslim-0.1.65 pyreadline3-3.5.4\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  50.9s\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.65...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  60.0s, saved as 'yolo11m.onnx' (38.6 MB)\n",
      "\n",
      "Export complete (65.0s)\n",
      "Results saved to \u001b[1mC:\\TASK_DETECT_DRONE\\CODES_DETECT_DRONE\\YOLO+calc_distance\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11m.onnx imgsz=640 half \n",
      "Validate:        yolo val task=detect model=yolo11m.onnx imgsz=640 data=/ultralytics/ultralytics/cfg/datasets/coco.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11m.onnx'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('yolo11m.pt') # or YOLO(path/to/best.pt)\n",
    "\n",
    "#export ncnn\n",
    "# model.export(format='ncnn',\n",
    "#              int8=False,\n",
    "#              dynamic=False,\n",
    "#              half = True,\n",
    "#              imgsz = 1024,\n",
    "#              device=device,\n",
    "#              batch = 1\n",
    "#              )\n",
    "\n",
    "# export onnx\n",
    "model.export(format='onnx',\n",
    "            #  imgsz=640,\n",
    "             half=True,\n",
    "             dynamic=True,\n",
    "             nms = True,\n",
    "             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c57e9350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "# load model ncnn format\n",
    "ncnn_model = YOLO('yolo11m_ncnn_model')\n",
    "\n",
    "# load model onnx format\n",
    "# onnx_model = YOLO('yolo11m.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_camera_process(idx_cam: int):\n",
    "    \"\"\"function to work in diferent process - capture frame and sent in queue\"\"\"\n",
    "    st = time.time()\n",
    "    cap = cv2.VideoCapture(idx_cam)#, cv2.CAP_DSHOW\n",
    "    st1 = time.time() - st\n",
    "    if not cap.isOpened():\n",
    "        print(f'Cam {idx_cam} not opened')\n",
    "        return\n",
    "    st2 = time.time() - st\n",
    "    #set params for cameras fps, width, height\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    st3  = time.time() - st\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    st4 = time.time() - st\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    st5 = time.time() - st\n",
    "\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    st6 = time.time() - st\n",
    "    # if fps == 0:\n",
    "    #     fps = 30\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    st7 = time.time() - st\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    st8 = time.time() - st\n",
    "    print(f\"[Процесс {idx_cam}] Подключено: {width}x{height} @ {fps}fps\")\n",
    "    start_time = time.time()\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    current_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = fr'record_cam1\\video_{current_time}.avi'\n",
    "    writer = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
    "    print(f'Prepaire writer: {time.time() - start_time} second')\n",
    "\n",
    "    count_cadr = 0\n",
    "    start_time = time.time()\n",
    "    print('loop while...')\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f'Not get frame')\n",
    "            break \n",
    "\n",
    "        result = ncnn_model(frame, conf=0.5, iou=0.2, imgsz=1024, verbose=True, device=device)\n",
    "        \n",
    "        cls = result[0].boxes.cls.cpu().numpy()\n",
    "        coords = result[0].boxes.xyxy.cpu().numpy()\n",
    "        for cl, (x, y, x1, y1) in zip(cls, coords):\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x1), int(y1)), (255, 0, 0), 1)\n",
    "            # Добавляем текст на кадре (можно и в главном процессе, но так легче)\n",
    "            \n",
    "            text_cls = str(cl)\n",
    "            cv2.putText(frame, text_cls, (int(x), int(y-3)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0),1)\n",
    "\n",
    "        text = f'Cam {idx_cam} | {width}x{height} @ {fps}fps'\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "        # if queue is full\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print('Exit by command user')\n",
    "            break\n",
    "        count_cadr += 1\n",
    "        delta_time = time.time() -start_time\n",
    "        print(f'Curent time: {delta_time}', end='\\r', flush=True)\n",
    "        cv2.imshow(f'video_time', frame)\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    end_time = time.time() - start_time\n",
    "    # print(f'st - {st}, \\nst1 - {st1}, \\nst2 - {st2}, \\nst3 - {st3}, \\nst4 - {st4}, \\nst5 - {st5}, \\nst6 - {st6}, \\nst7 - {st7}, \\nst8 - {st8}')\n",
    "    print(f'Process cam {idx_cam} END. \\nTime: {end_time} \\nCount cadr: {count_cadr}')\n",
    "    real_fps = count_cadr / end_time\n",
    "    print(f'Real fps: {real_fps}')\n",
    "\n",
    "\n",
    "\n",
    "capture_camera_process(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bd79c",
   "metadata": {},
   "source": [
    "No predict:\n",
    "[Процесс 0] Подключено: 1280x720 @ 30fps\n",
    "Prepaire writer: 0.0010001659393310547 second\n",
    "Exit by command user32980346686\n",
    "Process cam 0 END. \n",
    "Time: 30.57908797264099 \n",
    "Count cadr: 890\n",
    "Real fps: 29.104857567899998\n",
    "\n",
    "\n",
    "C predict:1024\n",
    "[Процесс 0] Подключено: 1280x720 @ 30fps\n",
    "Prepaire writer: 0.0030198097229003906 second\n",
    "Exit by command user19241333008\n",
    "Process cam 0 END. \n",
    "Time: 30.683942317962646 \n",
    "Count cadr: 423\n",
    "Real fps: 13.785712266587469\n",
    "\n",
    "\n",
    "predict 640\n",
    "[Процесс 1] Подключено: 640x480 @ 30fps\n",
    "Prepaire writer: 0.001001596450805664 second\n",
    "loop while...\n",
    "Exit by command user66066360474\n",
    "Process cam 1 END. \n",
    "Time: 30.737857580184937 \n",
    "Count cadr: 461\n",
    "Real fps: 14.997792178501802\n",
    "\n",
    "predict 224\n",
    "[Процесс 1] Подключено: 640x480 @ 30fps\n",
    "Prepaire writer: 0.0020008087158203125 second\n",
    "loop while...\n",
    "Exit by command user98002243042\n",
    "Process cam 1 END. \n",
    "Time: 30.767577648162842 \n",
    "Count cadr: 449\n",
    "Real fps: 14.59328404512242\n",
    "\n",
    "predict 1024 onnx export\n",
    "[Процесс 1] Подключено: 1280x720 @ 30fps\n",
    "Prepaire writer: 0.004999876022338867 second\n",
    "loop while...\n",
    "Loading yolo11m.onnx for ONNX Runtime inference...\n",
    "Using ONNX Runtime CUDAExecutionProvider\n",
    "Exit by command user67093658447\n",
    "Process cam 1 END. \n",
    "Time: 30.84447145462036 \n",
    "Count cadr: 334\n",
    "Real fps: 10.828520776937104\n",
    "\n",
    "predict 640 onnx export\n",
    "[Процесс 1] Подключено: 1280x720 @ 30fps\n",
    "Prepaire writer: 0.0019998550415039062 second\n",
    "loop while...\n",
    "Exit by command user97754287723\n",
    "Process cam 1 END. \n",
    "Time: 30.860729694366455 \n",
    "Count cadr: 526\n",
    "Real fps: 17.04431506349054\n",
    "\n",
    "\n",
    "Set 23 fps imgsz=640 format=onnx\n",
    "[Процесс 1] Подключено: 1280x720 @ 25fps\n",
    "Prepaire writer: 0.0010023117065429688 second\n",
    "loop while...\n",
    "Exit by command user97525787354\n",
    "Process cam 1 END. \n",
    "Time: 30.917776584625244 \n",
    "Count cadr: 526\n",
    "Real fps: 17.012866321751243\n",
    "\n",
    "\n",
    "\n",
    "1024\n",
    "image size = 1024 predict 52 - 55ms frame\n",
    "7.9ms preprocess, 34.5ms inference, 5.8ms postprocess per image at shape (1, 3, 768, 1024)\n",
    "Curent time: 0.9589450359344482\n",
    "0: 768x1024 1 person, 43.8ms\n",
    "Speed: 8.4ms preprocess, 43.8ms inference, 4.1ms postprocess per image at shape (1, 3, 768, 1024)\n",
    "Curent time: 1.051941156387329\n",
    "0: 768x1024 1 person, 1 remote, 37.6ms\n",
    "Speed: 11.3ms preprocess, 37.6ms inference, 3.7ms postprocess \n",
    "\n",
    "640\n",
    "predict ~ 48 ms\n",
    "Speed: 2.0ms preprocess, 32.4ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
    "Curent time: 0.8921859264373779\n",
    "0: 480x640 1 person, 1 remote, 32.0ms\n",
    "Speed: 2.2ms preprocess, 32.0ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
    "Curent time: 0.9621872901916504\n",
    "0: 480x640 1 person, 1 remote, 40.9ms\n",
    "Speed: 2.2ms preprocess, 40.9ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
    "Curent time: 1.0502090454101562\n",
    "0: 480x640 1 person, 1 remote, 39.9ms\n",
    "Speed: 3.4ms preprocess, 39.9ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
    "Curent time: 1.1407248973846436\n",
    "\n",
    "\n",
    "\n",
    "640 onnx format\n",
    "predict ~ 31 ms\n",
    "Speed: 1.9ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
    "Curent time: 0.8115992546081543\n",
    "0: 384x640 1 person, 28.5ms\n",
    "Speed: 1.9ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
    "Curent time: 0.8685996532440186\n",
    "0: 384x640 1 person, 26.8ms\n",
    "Speed: 1.9ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
    "Curent time: 0.9225924015045166\n",
    "0: 384x640 1 person, 25.9ms\n",
    "Speed: 1.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
    "Curent time: 0.9755916595458984\n",
    "0: 384x640 1 person, 30.0ms\n",
    "Speed: 1.9ms preprocess, 30.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
    "Curent time: 1.0335912704467773\n",
    "\n",
    "\n",
    "\n",
    "1024 ncnn format\n",
    "predict ~ 1370\n",
    "Speed: 14.0ms preprocess, 1338.9ms inference, 4.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
    "Curent time: 5.110432863235474\n",
    "0: 1024x1024 1 person, 1324.1ms\n",
    "Speed: 13.0ms preprocess, 1324.1ms inference, 4.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
    "Curent time: 6.483858585357666\n",
    "0: 1024x1024 1 person, 1339.0ms\n",
    "Speed: 12.3ms preprocess, 1339.0ms inference, 4.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
    "Curent time: 7.870999336242676\n",
    "0: 1024x1024 1 person, 1351.2ms\n",
    "Speed: 14.2ms preprocess, 1351.2ms inference, 5.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
    "Curent time: 9.275911331176758\n",
    "0: 1024x1024 1 person, 1363.8ms\n",
    "Speed: 14.4ms preprocess, 1363.8ms inference, 4.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
    "...\n",
    "Process cam 1 END. \n",
    "Time: 34.312185764312744 \n",
    "Count cadr: 23\n",
    "Real fps: 0.6703157927036444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ca1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid = r'C:\\TASK_DETECT_DRONE\\CODES_DETECT_DRONE\\YOLO+calc_distance\\record_cam1\\video_20250825_122051.avi'\n",
    "cap = cv2.VideoCapture(vid)\n",
    "count_cadrs = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "count_cadrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944ad102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/1\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate,nb_frames -of default=noprint_wrappers=1:nokey=1 {vid}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b55642",
   "metadata": {},
   "source": [
    "тест отдельно по камерам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1513e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was pressed key quit\n"
     ]
    }
   ],
   "source": [
    "idx_cam = 0\n",
    "cap = cv2.VideoCapture(idx_cam)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error open camera {idx_cam}\")\n",
    "    # return\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "font = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')  #MP4V   пропуск кадров\n",
    "# output_video = rf'{path_save_video}\\video_cam_{idx_cam}.avi'  # пропуск кадров\n",
    "# writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))  # пропуск кадров\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f'Lost connetct with camera id: {idx_cam}')\n",
    "        break\n",
    "    text = f'{str(fps)} : {str(height)} : {str(width)} '\n",
    "    cv2.putText(frame, text, (10, 30), font, 1.0, (255, 0, 0), 1)\n",
    "\n",
    "    # writer.write(frame)  # пропуск кадров\n",
    "\n",
    "    # clearing the queue (чтоб не тормозила камера) so that the camera doesn't slow down\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Was pressed key quit\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(f'camera_{str(idx_cam)}', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8eaea",
   "metadata": {},
   "source": [
    "define function for visualize from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab0bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cam_1 = 0\n",
    "idx_cam_2 = 1\n",
    "\n",
    "frame_queue1 = queue.Queue(maxsize=1)\n",
    "frame_queue2 = queue.Queue(maxsize=1)\n",
    "\n",
    "writers={}\n",
    "\n",
    "def capture_camera(idx_cam: int, frame_queue):\n",
    "    cap = cv2.VideoCapture(idx_cam)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error open camera {idx_cam}\")\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')  #MP4V   пропуск кадров\n",
    "    # output_video = rf'{path_save_video}\\video_cam_{idx_cam}.avi'  # пропуск кадров\n",
    "    # writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))  # пропуск кадров\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f'Lost connetct with camera id: {idx_cam}')\n",
    "            break\n",
    "        text = f'{str(fps)} : {str(height)} : {str(width)} '\n",
    "        cv2.putText(frame, text, (10, 30), font, 1.0, (255, 0, 0), 1)\n",
    "\n",
    "        # writer.write(frame)  # пропуск кадров\n",
    "\n",
    "        # clearing the queue (чтоб не тормозила камера) so that the camera doesn't slow down\n",
    "        if not frame_queue.empty():\n",
    "            frame_queue.get()\n",
    "        \n",
    "        frame_queue.put((idx_cam, frame))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Was pressed key quit\")\n",
    "            break\n",
    "\n",
    "        # cv2.imshow(f'camera_{str(idx_cam)}', frame)\n",
    "    \n",
    "    cap.release()\n",
    "    # writer.release()   # пропуск кадров\n",
    "    # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b603271",
   "metadata": {},
   "source": [
    "### Example with threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67a0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record start: record_cam1\\camera_0_20250724_143334.mp4\n",
      "Record avi start: record_cam2\\camera_1_20250724_143334.avi\n"
     ]
    }
   ],
   "source": [
    "# start threading\n",
    "idx_cam_1 = 0\n",
    "idx_cam_2 = 1\n",
    "\n",
    "frame_queue1 = queue.Queue(maxsize=1)\n",
    "frame_queue2 = queue.Queue(maxsize=1)\n",
    "\n",
    "writers={}\n",
    "\n",
    "def capture_camera(idx_cam: int, frame_queue):\n",
    "    cap = cv2.VideoCapture(idx_cam)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error open camera {idx_cam}\")\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')  #MP4V   пропуск кадров\n",
    "    # output_video = rf'{path_save_video}\\video_cam_{idx_cam}.avi'  # пропуск кадров\n",
    "    # writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))  # пропуск кадров\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f'Lost connetct with camera id: {idx_cam}')\n",
    "            break\n",
    "        text = f'{str(fps)} : {str(height)} : {str(width)} '\n",
    "        cv2.putText(frame, text, (10, 30), font, 1.0, (255, 0, 0), 1)\n",
    "\n",
    "        # writer.write(frame)  # пропуск кадров\n",
    "\n",
    "        # clearing the queue (чтоб не тормозила камера) so that the camera doesn't slow down\n",
    "        if not frame_queue.empty():\n",
    "            frame_queue.get()\n",
    "        \n",
    "        frame_queue.put((idx_cam, frame))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Was pressed key quit\")\n",
    "            break\n",
    "\n",
    "        # cv2.imshow(f'camera_{str(idx_cam)}', frame)\n",
    "    \n",
    "    cap.release()\n",
    "    # writer.release()   # пропуск кадров\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    path_save1 = r'record_cam1'\n",
    "    path_save2 = r'record_cam2'\n",
    "\n",
    "    t1 = threading.Thread(target=capture_camera, args=(idx_cam_1, frame_queue1), daemon=True)\n",
    "    t2 = threading.Thread(target=capture_camera, args=(idx_cam_2, frame_queue2), daemon=True)\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    # Main loop visualize\n",
    "    try:\n",
    "        while True:\n",
    "            current_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            \n",
    "\n",
    "            if not frame_queue1.empty():\n",
    "                idx, frame = frame_queue1.get()\n",
    "                cv2.imshow(f'Camera_{idx}', frame)\n",
    "\n",
    "                #Initialize VideoWriter \n",
    "                if idx not in writers:\n",
    "                    filename = fr'{path_save1}\\camera_{idx}_{current_time}.mp4'\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'H264')  # XVID\n",
    "                    writers[idx] = cv2.VideoWriter(filename, fourcc, 30, (frame.shape[1], frame.shape[0]))\n",
    "                    print(f'Record start: {filename}')\n",
    "                \n",
    "                writers[idx].write(frame)\n",
    "            \n",
    "            if not frame_queue2.empty():\n",
    "                idx, frame = frame_queue2.get()\n",
    "                cv2.imshow(f'Camera_{idx}', frame)\n",
    "\n",
    "                #init vwr\n",
    "                if idx not in writers:\n",
    "                    filename = fr'{path_save2}\\camera_{idx}_{current_time}.avi'\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                    writers[idx] = cv2.VideoWriter(filename, fourcc, 30, (frame.shape[1], frame.shape[0]))\n",
    "                    print(f'Record avi start: {filename}')\n",
    "                \n",
    "                writers[idx].write(frame)\n",
    "\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            time.sleep(0.01) \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    for writer in writers.values():\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f8f75",
   "metadata": {},
   "source": [
    "Если камеры подключены по сети (IP-камеры), то cv2.VideoCapture(idx_cam) может работать нестабильно — лучше использовать cv2.CAP_FFMPEG или cv2.CAP_DSHOW в зависимости от платформы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4eead",
   "metadata": {},
   "source": [
    "### use multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d87ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f31941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_camera_process(idx_cam: int, queue: mp.Queue):\n",
    "    \"\"\"function to work in diferent process - capture frame and sent in queue\"\"\"\n",
    "    cap = cv2.VideoCapture(idx_cam)\n",
    "    if not cap.isOpened():\n",
    "        print(f'Cam {idx_cam} not opened')\n",
    "        return\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"[Процесс {idx_cam}] Подключено: {width}x{height} @ {fps}fps\")\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f'Not get frame')\n",
    "            break\n",
    "        # Добавляем текст на кадре (можно и в главном процессе, но так легче)\n",
    "        text = f'Cam {idx_cam} | {width}x{height} @ {fps}fps'\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "        # if queue is full\n",
    "        if not queue.empty():\n",
    "            queue.get() # cleareing queue\n",
    "        queue.put((idx_cam, frame))\n",
    "\n",
    "        \n",
    "        time.sleep(0.01)\n",
    "    cap.release()\n",
    "    queue.put((idx_cam, None)) # Signal to end\n",
    "    print(f'Process cam {idx_cam} END.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a813cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processes to capture cadrs. Press \"q\" to exit\n",
      "Stopped USER\n",
      "Resourses to free\n"
     ]
    }
   ],
   "source": [
    "mp.set_start_method('spawn', force=True)  # Критично для Windows/macOS\n",
    "idx_cam_1 = 0\n",
    "idx_cam_2 = 1\n",
    "\n",
    "# Создаём очереди для передачи кадров из процессов\n",
    "queue1 = mp.Queue(maxsize=1)\n",
    "queue2 = mp.Queue(maxsize=1)\n",
    "\n",
    "# Запускаем процессы\n",
    "proc1 = mp.Process(target=capture_camera_process, args=(idx_cam_1, queue1), daemon=True)\n",
    "proc2 = mp.Process(target=capture_camera_process, args=(idx_cam_2, queue2), daemon=True)\n",
    "\n",
    "proc1.start()\n",
    "proc2.start()\n",
    "\n",
    "print('Start processes to capture cadrs. Press \"q\" to exit')\n",
    "try:\n",
    "    while True:\n",
    "        frame1 = None\n",
    "        frame2 = None\n",
    "\n",
    "        if not queue1.empty():\n",
    "            cam_id, frame1 = queue1.get()\n",
    "            \n",
    "            if frame1 is None:\n",
    "                print('Camera 1 is stop')\n",
    "                break\n",
    "        \n",
    "        if not queue2.empty():\n",
    "            cam_id, frame2 = queue2.get()\n",
    "            if frame2 is None:\n",
    "                print('Camera 2 is stop')\n",
    "                break\n",
    "\n",
    "        if frame1 is not None:\n",
    "            cv2.imshow(f'Camera_{cam_id}', frame1)\n",
    "        if frame2 is not None:\n",
    "            cv2.imshow(f'Camera {cam_id}', frame2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print('Exit by command user')\n",
    "            break\n",
    "        time.sleep(0.01)\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped USER')\n",
    "\n",
    "finally:\n",
    "    # stoped processes\n",
    "    cv2.destroyAllWindows()\n",
    "    proc1.terminate()\n",
    "    proc2.terminate()\n",
    "    proc1.join(timeout=1)\n",
    "    proc2.join(timeout=1)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Resourses to free')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f645463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf37e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85d95934",
   "metadata": {},
   "source": [
    "Пример изменения источника камеры по нажатию клавиши, НЕ ТАК КАК НАДО работает, просто пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77924880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press space for change camera. Ctrl+C for exit.\n",
      "Release camera 1\n",
      "Press quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cam = \"camera_1\"\n",
    "\n",
    "def on_press(key):\n",
    "    global cam\n",
    "    try:\n",
    "        if key.char == ' ': #\n",
    "            if cam == 'camera_1':\n",
    "                cam == 'camera_2'\n",
    "                get_video(idx_cam_2)\n",
    "            else:\n",
    "                get_video(idx_cam_1)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "listener = keyboard.Listener(on_press=on_press)\n",
    "listener.start()\n",
    "\n",
    "print(f'Press space for change camera. Ctrl+C for exit.')\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if cam == 'camera_1':\n",
    "            print(f'Release camera 1')\n",
    "            get_video(idx_cam_1)\n",
    "        else:\n",
    "            print(f'Release camera 2')\n",
    "            get_video(idx_cam_2)\n",
    "except KeyboardInterrupt:\n",
    "    listener.stop()\n",
    "    print(\"\\nExit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ea352",
   "metadata": {},
   "source": [
    "Если камеры подключены по сети (IP-камеры), то cv2.VideoCapture(idx_cam) может работать нестабильно — лучше использовать cv2.CAP_FFMPEG или cv2.CAP_DSHOW в зависимости от платформы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e556b2b",
   "metadata": {},
   "source": [
    "Read count frames in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8b6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/1\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\TASK_DETECT_DRONE\\CODES_DETECT_DRONE\\YOLO+calc_distance\\record_cam1\\camera_0_20250825_104555.avi'\n",
    "! ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate,nb_frames -of default=noprint_wrappers=1:nokey=1 {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad6967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/1\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\TASK_DETECT_DRONE\\CODES_DETECT_DRONE\\YOLO+calc_distance\\record_cam1\\camera_0_20250825_112356.avi'\n",
    "! ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate,nb_frames -of default=noprint_wrappers=1:nokey=1 {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa08f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps = 30.0, \n",
      "duration video in second:  5.166666666666667\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "path = r'C:\\TASK_DETECT_DRONE\\CODES_DETECT_DRONE\\YOLO+calc_distance\\record_cam1\\camera_0_20250825_104555.avi'\n",
    "def describe_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print('cap is not opened')\n",
    "\n",
    "    count_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration_sec = count_frames / fps\n",
    "    print(f'fps = {fps}, \\nduration video in second:  {duration_sec}')\n",
    "\n",
    "describe_video(path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_detect_drone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
